{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b543fb72",
   "metadata": {},
   "source": [
    "# Logistic regression model\n",
    "Procedure:\n",
    "\n",
    "\n",
    "Example: Alzheimers mass spectrometry-based proteomics dataset\n",
    "\n",
    "> Predict Alzheimer disease based on proteomics measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90b1b6",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Setup colab installation\n",
    "# You need to restart the runtime after running this cell\n",
    "# (due to a pandas 1.5.3 and matplotlib >3.7 incompability - 23-11-07)\n",
    "%pip install njab heatmapz openpyxl \"matplotlib<3.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc78871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from heatmap import corrplot\n",
    "import umap\n",
    "\n",
    "import sklearn\n",
    "import sklearn.impute\n",
    "from sklearn.metrics import make_scorer, log_loss\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import njab.sklearn\n",
    "from njab.sklearn import StandardScaler\n",
    "from njab.sklearn import pca as njab_pca\n",
    "from njab.sklearn.scoring import ConfusionMatrix\n",
    "from njab.sklearn.types import Splits\n",
    "from njab.plotting.metrics import plot_auc, plot_prc\n",
    "from njab.sklearn.scoring import get_score, get_pred, get_target_count_per_bin\n",
    "\n",
    "logger = logging.getLogger('njab')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "njab.plotting.set_font_sizes('x-small')\n",
    "seaborn.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd67d14",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479171d3",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "CLINIC: str = 'https://raw.githubusercontent.com/RasmussenLab/njab/HEAD/docs/tutorial/data/alzheimer/meta.csv'  # clincial data\n",
    "fname_omics: str = 'https://raw.githubusercontent.com/RasmussenLab/njab/HEAD/docs/tutorial/data/alzheimer/proteome.csv'  # omics data\n",
    "TARGET: str = '_primary biochemical AD classification'  # target column in CLINIC data\n",
    "n_features_max: int = 15\n",
    "VAL_IDS: str = ''  #\n",
    "VAL_IDS_query: str = ''\n",
    "weights: bool = True\n",
    "FOLDER = 'alzheimer'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25d1d83",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd03726",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic = pd.read_csv(CLINIC, index_col=0)\n",
    "cols_clinic = njab.pandas.get_colums_accessor(clinic)\n",
    "omics = pd.read_csv(fname_omics, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9733ac",
   "metadata": {},
   "source": [
    "Data shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4fc76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics.shape, clinic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57daf2b",
   "metadata": {},
   "source": [
    "See how common omics features are and remove feature below choosen frequency cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e73155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = omics.notna().sum().sort_values().plot(rot=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12c754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_cutoff = 0.5\n",
    "M_before = omics.shape[1]\n",
    "omics = omics.dropna(thresh=int(len(omics) * freq_cutoff), axis=1)\n",
    "M_after = omics.shape[1]\n",
    "msg = (\n",
    "    f\"Removed {M_before-M_after} features with more than {freq_cutoff*100}% missing values.\"\n",
    "    f\"\\nRemaining features: {M_after} (of {M_before})\")\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7beafb",
   "metadata": {},
   "source": [
    "## Clinical data\n",
    "View clinical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13fb7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3c0e95",
   "metadata": {},
   "source": [
    "## Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58064aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "njab.pandas.value_counts_with_margins(clinic[TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3f912",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_counts = clinic[TARGET].value_counts()\n",
    "\n",
    "if target_counts.sum() < len(clinic):\n",
    "    print(\"Target has missing values.\"\n",
    "          f\" Can only use {target_counts.sum()} of {len(clinic)} samples.\")\n",
    "    mask = clinic[TARGET].notna()\n",
    "    clinic, omics = clinic.loc[mask], omics.loc[mask]\n",
    "\n",
    "TARGET_LABEL = 'AD'\n",
    "\n",
    "y_obj = clinic[TARGET].rename(TARGET_LABEL)\n",
    "y = pd.get_dummies(y_obj)[\"biochemical AD\"].rename(TARGET_LABEL)\n",
    "\n",
    "target_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410f6149",
   "metadata": {},
   "source": [
    "Encode some clincial variables as binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfca3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_collection_site = pd.get_dummies(\n",
    "    clinic['_collection site'])  # reference is first column (Berlin)\n",
    "dummies_collection_site.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443c8da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_for_ml = dummies_collection_site.iloc[:, 1:]\n",
    "clinic_for_ml = (clinic_for_ml.join(\n",
    "    pd.get_dummies(clinic['_gender']).rename(columns={\n",
    "        'f': 'female',\n",
    "        'm': 'male'\n",
    "    }).iloc[:, 1:])).assign(age=clinic['_age at CSF collection'])\n",
    "clinic_for_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decb5a8d",
   "metadata": {},
   "source": [
    "## Test IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d4eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "olink_val, clinic_val = None, None\n",
    "if not VAL_IDS:\n",
    "    if VAL_IDS_query:\n",
    "        logging.warning(f\"Querying index using: {VAL_IDS_query}\")\n",
    "        VAL_IDS = clinic.filter(like='Cflow', axis=0).index.to_list()\n",
    "        logging.warning(f\"Found {len(VAL_IDS)} Test-IDs\")\n",
    "    else:\n",
    "        logging.warning(\"Create train and test split.\")\n",
    "        _, VAL_IDS = sklearn.model_selection.train_test_split(\n",
    "            clinic.index,\n",
    "            test_size=0.2,\n",
    "            random_state=123,\n",
    "            stratify=clinic[TARGET])\n",
    "        VAL_IDS = list(VAL_IDS)\n",
    "elif isinstance(VAL_IDS, str):\n",
    "    VAL_IDS = VAL_IDS.split(\",\")\n",
    "else:\n",
    "    raise ValueError(\"Provide IDs in csv format as str: 'ID1,ID2'\")\n",
    "VAL_IDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df7f7c3",
   "metadata": {},
   "source": [
    "## Combine clinical and olink data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bdaf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case you need to subselect\n",
    "feat_to_consider = clinic_for_ml.columns.to_list()\n",
    "feat_to_consider += omics.columns.to_list()\n",
    "feat_to_consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1351ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictors = feat_clinic + olink.columns.to_list()\n",
    "model_name = 'all'\n",
    "X = clinic_for_ml.join(omics)[feat_to_consider]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f3e22b",
   "metadata": {},
   "source": [
    "## Data Splits -> train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f1a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LABEL = 'train'\n",
    "TEST_LABEL = 'test'\n",
    "if VAL_IDS:\n",
    "    diff = pd.Index(VAL_IDS)\n",
    "    VAL_IDS = X.index.intersection(VAL_IDS)\n",
    "    if len(diff) < len(VAL_IDS):\n",
    "        logging.warning(\"Some requested validation IDs are not in the data: \"\n",
    "                        \",\".join(str(x) for x in diff.difference(VAL_IDS)))\n",
    "    X_val = X.loc[VAL_IDS]\n",
    "    X = X.drop(VAL_IDS)\n",
    "\n",
    "    use_val_split = True\n",
    "\n",
    "    y_val = y.loc[VAL_IDS]\n",
    "    y_obj_val = y_obj.loc[VAL_IDS]\n",
    "    y = y.drop(VAL_IDS)\n",
    "    y_obj = y_obj.drop(VAL_IDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4bd650",
   "metadata": {},
   "source": [
    "## Output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb94cf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = Path(FOLDER)\n",
    "FOLDER.mkdir(exist_ok=True, parents=True)\n",
    "FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3017e69",
   "metadata": {},
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae0d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out\n",
    "files_out = {}\n",
    "fname = FOLDER / 'log_reg.xlsx'\n",
    "files_out[fname.stem] = fname\n",
    "writer = pd.ExcelWriter(fname)\n",
    "fname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0313041",
   "metadata": {},
   "source": [
    "## Collect test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbe5b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = y_val.to_frame('true')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d87456a",
   "metadata": {},
   "source": [
    "## Deal with missing values globally - impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb401c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_w_missings = X.isna().sum()\n",
    "feat_w_missings = feat_w_missings.loc[feat_w_missings > 0]\n",
    "feat_w_missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9131bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_w_missing = X.isna().sum(axis=1).astype(bool)\n",
    "col_w_missing = X.isna().sum(axis=0).astype(bool)\n",
    "X.loc[row_w_missing, col_w_missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c129725",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_imputer = sklearn.impute.SimpleImputer(strategy='median')\n",
    "\n",
    "X = njab.sklearn.transform_DataFrame(X, median_imputer.fit_transform)\n",
    "X_val = njab.sklearn.transform_DataFrame(X_val, median_imputer.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399775b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X.isna().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feea514",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af76623e",
   "metadata": {},
   "source": [
    "## Principal Components\n",
    "\n",
    "- [ ]  base on selected data\n",
    "- binary features do not strictly need to be normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c0c701",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "PCs, pca = njab_pca.run_pca(X_scaled, n_components=None)\n",
    "files_out[\"var_explained_by_PCs.pdf\"] = FOLDER / \"var_explained_by_PCs.pdf\"\n",
    "ax = njab_pca.plot_explained_variance(pca)\n",
    "ax.locator_params(axis='x', integer=True)\n",
    "njab.plotting.savefig(ax.get_figure(), files_out[\"var_explained_by_PCs.pdf\"])\n",
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13270190",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_out['scatter_first_5PCs.pdf'] = FOLDER / 'scatter_first_5PCs.pdf'\n",
    "\n",
    "fig, axes = plt.subplots(5, 2, figsize=(8.3, 11.7), layout='constrained')\n",
    "PCs = PCs.join(y.astype('category'))\n",
    "up_to = min(PCs.shape[-1], 5)\n",
    "# https://github.com/matplotlib/matplotlib/issues/25538\n",
    "# colab: old pandas version and too new matplotlib version (2023-11-6)\n",
    "for (i, j), ax in zip(itertools.combinations(range(up_to), 2), axes.flatten()):\n",
    "    PCs.plot.scatter(i, j, c=TARGET_LABEL, cmap='Paired', ax=ax)\n",
    "_ = PCs.pop(TARGET_LABEL)\n",
    "njab.plotting.savefig(fig, files_out['scatter_first_5PCs.pdf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480dedba",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74d8c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5684ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_out['umap.pdf'] = FOLDER / 'umap.pdf'\n",
    "\n",
    "embedding = pd.DataFrame(embedding,\n",
    "                         index=X_scaled.index,\n",
    "                         columns=['UMAP 1',\n",
    "                                  'UMAP 2']).join(y.astype('category'))\n",
    "ax = embedding.plot.scatter('UMAP 1', 'UMAP 2', c=TARGET_LABEL, cmap='Paired')\n",
    "njab.plotting.savefig(ax.get_figure(), files_out['umap.pdf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39575329",
   "metadata": {},
   "source": [
    "## Baseline Model - Logistic Regression\n",
    "- `age`, `decompensated`, `MELD-score`\n",
    "- use weigthing to counter class imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9affe828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run nb with parameters\n",
    "# name_model = 'baseline'\n",
    "# cols_base_model = [cols_clinic.Age, cols_clinic.DecomensatedAtDiagnosis, cols_clinic.MELD_score] # MELD score -> death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if weights:\n",
    "    weights = 'balanced'\n",
    "    cutoff = 0.5\n",
    "else:\n",
    "    cutoff = None\n",
    "    weights = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12514e6d",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Procedure:\n",
    "1. Select best set of features from entire feature set selected using CV on train split\n",
    "2. Retrain best model configuration using entire train split and evalute on test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe410fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Scaled Data\n",
    "splits = Splits(X_train=X_scaled,\n",
    "                X_test=scaler.transform(X_val),\n",
    "                y_train=y,\n",
    "                y_test=y_val)\n",
    "\n",
    "# splits = Splits(X_train=X,\n",
    "#                 X_test=X_val,\n",
    "#                 y_train=y, y_test=y_val)\n",
    "\n",
    "model = sklearn.linear_model.LogisticRegression(penalty='l2',\n",
    "                                                class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1152d78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = [\n",
    "    'precision', 'recall', 'f1', 'balanced_accuracy', 'roc_auc',\n",
    "    'average_precision'\n",
    "]\n",
    "scoring = {k: k for k in scoring}\n",
    "# do not average log loss for AIC and BIC calculations\n",
    "scoring['log_loss'] = make_scorer(log_loss,\n",
    "                                  greater_is_better=True,\n",
    "                                  normalize=False)\n",
    "cv_feat = njab.sklearn.find_n_best_features(\n",
    "    X=splits.X_train,\n",
    "    y=splits.y_train,\n",
    "    model=model,\n",
    "    name=TARGET_LABEL,\n",
    "    groups=y,\n",
    "    n_features_max=n_features_max,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True,\n",
    "    # fit_params=dict(sample_weight=weights)\n",
    ")\n",
    "cv_feat = cv_feat.drop('test_case',\n",
    "                       axis=1).groupby('n_features').agg(['mean', 'std'])\n",
    "cv_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa1a6e1",
   "metadata": {},
   "source": [
    "Add AIC and BIC for model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d3b622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIC vs BIC on train and test data with bigger is better\n",
    "IC_criteria = pd.DataFrame()\n",
    "N_split = {\n",
    "    'train': round(len(splits.X_train) * 0.8),\n",
    "    'test': round(len(splits.X_train) * 0.2)\n",
    "}\n",
    "\n",
    "for _split in ('train', 'test'):\n",
    "\n",
    "    IC_criteria[(f'{_split}_neg_AIC',\n",
    "                 'mean')] = -(2 * cv_feat.index.to_series() -\n",
    "                              2 * cv_feat[(f'{_split}_log_loss', 'mean')])\n",
    "    IC_criteria[(\n",
    "        f'{_split}_neg_BIC',\n",
    "        'mean')] = -(cv_feat.index.to_series() * np.log(N_split[_split]) -\n",
    "                     2 * cv_feat[(f'{_split}_log_loss', 'mean')])\n",
    "IC_criteria.columns = pd.MultiIndex.from_tuples(IC_criteria.columns)\n",
    "IC_criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec328442",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_feat = cv_feat.join(IC_criteria)\n",
    "cv_feat = cv_feat.filter(regex=\"train|test\", axis=1).style.highlight_max(\n",
    "    axis=0, subset=pd.IndexSlice[:, pd.IndexSlice[:, 'mean']])\n",
    "cv_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74372296",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_feat.to_excel(writer, 'CV', float_format='%.3f')\n",
    "cv_feat = cv_feat.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbfe4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cv_feat.columns.levels[0].str[:4] == 'test'\n",
    "scores_cols = cv_feat.columns.levels[0][mask]\n",
    "n_feat_best = cv_feat.loc[:, pd.IndexSlice[scores_cols, 'mean']].idxmax()\n",
    "n_feat_best.name = 'best'\n",
    "n_feat_best.to_excel(writer, 'n_feat_best')\n",
    "n_feat_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0b48e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_model = njab.sklearn.run_model(\n",
    "    model=model,\n",
    "    splits=splits,\n",
    "    # n_feat_to_select=n_feat_best.loc['test_f1', 'mean'],\n",
    "    n_feat_to_select=n_feat_best.loc['test_roc_auc', 'mean'],\n",
    "    # n_feat_to_select=n_feat_best.loc['test_neg_AIC', 'mean'],\n",
    "    # n_feat_to_select=int(n_feat_best.mode()),\n",
    "    # fit_params=dict(sample_weight=weights)\n",
    ")\n",
    "\n",
    "results_model.name = model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a95d628",
   "metadata": {},
   "source": [
    "## ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf6ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_auc(results_model,\n",
    "              label_train=TRAIN_LABEL,\n",
    "              label_test=TEST_LABEL,\n",
    "              figsize=(4, 2))\n",
    "files_out['ROAUC'] = FOLDER / 'plot_roauc.pdf'\n",
    "njab.plotting.savefig(ax.get_figure(), files_out['ROAUC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1810402",
   "metadata": {},
   "source": [
    "## PRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84c3ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_prc(results_model,\n",
    "              label_train=TRAIN_LABEL,\n",
    "              label_test=TEST_LABEL,\n",
    "              figsize=(4, 2))\n",
    "files_out['PRAUC'] = FOLDER / 'plot_prauc.pdf'\n",
    "njab.plotting.savefig(ax.get_figure(), files_out['PRAUC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4449d86c",
   "metadata": {},
   "source": [
    "## Coefficients with/out std. errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b43a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'coef': results_model.model.coef_.flatten(),\n",
    "    'name': results_model.model.feature_names_in_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e92091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_model.model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51a93bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_logit = sm.Logit(endog=splits.y_train,\n",
    "                    exog=sm.add_constant(\n",
    "                        splits.X_train[results_model.selected_features]))\n",
    "sm_logit = sm_logit.fit()\n",
    "sm_logit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56817edd",
   "metadata": {},
   "source": [
    "## Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e792d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "des_selected_feat = splits.X_train[results_model.selected_features].describe()\n",
    "des_selected_feat.to_excel(writer, 'sel_feat', float_format='%.3f')\n",
    "des_selected_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6aa59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "files_out['corr_plot_train.pdf'] = FOLDER / 'corr_plot_train.pdf'\n",
    "_ = corrplot(X[results_model.selected_features].join(y).corr(), size_scale=300)\n",
    "njab.plotting.savefig(fig, files_out['corr_plot_train.pdf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3598b5b",
   "metadata": {},
   "source": [
    "## Plot training data scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c05f839",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BINS = 20\n",
    "score = get_score(clf=results_model.model,\n",
    "                  X=splits.X_train[results_model.selected_features],\n",
    "                  pos=1)\n",
    "ax = score.hist(bins=N_BINS)\n",
    "files_out['hist_score_train.pdf'] = FOLDER / 'hist_score_train.pdf'\n",
    "njab.plotting.savefig(ax.get_figure(), files_out['hist_score_train.pdf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef3f684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_val\n",
    "pred_bins = get_target_count_per_bin(score, y, n_bins=N_BINS)\n",
    "ax = pred_bins.plot(kind='bar', ylabel='count')\n",
    "files_out[\n",
    "    'hist_score_train_target.pdf'] = FOLDER / 'hist_score_train_target.pdf'\n",
    "njab.plotting.savefig(ax.get_figure(),\n",
    "                      files_out['hist_score_train_target.pdf'])\n",
    "# pred_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce7379e",
   "metadata": {},
   "source": [
    "## Test data scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f20da4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_val = get_score(clf=results_model.model,\n",
    "                      X=splits.X_test[results_model.selected_features],\n",
    "                      pos=1)\n",
    "predictions['score'] = score_val\n",
    "ax = score_val.hist(bins=N_BINS)  # list(x/N_BINS for x in range(0,N_BINS)))\n",
    "ax.set_ylabel('count')\n",
    "ax.set_xlim(0, 1)\n",
    "files_out['hist_score_test.pdf'] = FOLDER / 'hist_score_test.pdf'\n",
    "njab.plotting.savefig(ax.get_figure(), files_out['hist_score_test.pdf'])\n",
    "pred_bins_val = get_target_count_per_bin(score_val, y_val, n_bins=N_BINS)\n",
    "ax = pred_bins_val.plot(kind='bar', ylabel='count')\n",
    "ax.locator_params(axis='y', integer=True)\n",
    "files_out['hist_score_test_target.pdf'] = FOLDER / 'hist_score_test_target.pdf'\n",
    "njab.plotting.savefig(ax.get_figure(), files_out['hist_score_test_target.pdf'])\n",
    "# pred_bins_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53800467",
   "metadata": {},
   "source": [
    "## Performance evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1adaa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "prc = pd.DataFrame(results_model.train.prc,\n",
    "                   index='precision recall cutoffs'.split())\n",
    "prc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb58cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prc.loc['f1_score'] = 2 * (prc.loc['precision'] * prc.loc['recall']) / (\n",
    "    1 / prc.loc['precision'] + 1 / prc.loc['recall'])\n",
    "f1_max = prc[prc.loc['f1_score'].argmax()]\n",
    "f1_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4ef6ad",
   "metadata": {},
   "source": [
    "Cutoff set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9212bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = float(f1_max.loc['cutoffs'])\n",
    "cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc5bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = njab.sklearn.scoring.get_custom_pred(\n",
    "    clf=results_model.model,\n",
    "    X=splits.X_test[results_model.selected_features],\n",
    "    cutoff=cutoff)\n",
    "predictions[model_name] = y_pred_val\n",
    "predictions['dead'] = y_val\n",
    "_ = ConfusionMatrix(y_val, y_pred_val).as_dataframe()\n",
    "_.columns = pd.MultiIndex.from_tuples([(t[0] + f\" - {cutoff:.3f}\", t[1])\n",
    "                                       for t in _.columns])\n",
    "_.to_excel(writer, \"CM_test_cutoff_adapted\")\n",
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0082d20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = get_pred(clf=results_model.model,\n",
    "                      X=splits.X_test[results_model.selected_features])\n",
    "predictions[model_name] = y_pred_val\n",
    "predictions['dead'] = y_val\n",
    "_ = ConfusionMatrix(y_val, y_pred_val).as_dataframe()\n",
    "_.columns = pd.MultiIndex.from_tuples([(t[0] + f\" - {0.5}\", t[1])\n",
    "                                       for t in _.columns])\n",
    "_.to_excel(writer, \"CM_test_cutoff_0.5\")\n",
    "_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1326dcd",
   "metadata": {},
   "source": [
    "## Multiplicative decompositon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a69f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_lr_multiplicative_decomposition(results, X, score, y):\n",
    "    components = X[results.selected_features].multiply(results.model.coef_)\n",
    "    components['intercept'] = float(results.model.intercept_)\n",
    "    components = np.exp(components)\n",
    "    components['score'] = score\n",
    "    components[TARGET] = y\n",
    "    components = components.sort_values('score', ascending=False)\n",
    "    return components\n",
    "\n",
    "\n",
    "components = get_lr_multiplicative_decomposition(results=results_model,\n",
    "                                                 X=splits.X_train,\n",
    "                                                 score=score,\n",
    "                                                 y=y)\n",
    "components.to_excel(writer, 'decomp_multiplicative_train')\n",
    "components.to_excel(writer,\n",
    "                    'decomp_multiplicative_train_view',\n",
    "                    float_format='%.5f')\n",
    "components.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fac3d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "components_test = get_lr_multiplicative_decomposition(results=results_model,\n",
    "                                                      X=splits.X_test,\n",
    "                                                      score=score_val,\n",
    "                                                      y=y_val)\n",
    "components_test.to_excel(writer, 'decomp_multiplicative_test')\n",
    "components_test.to_excel(writer,\n",
    "                         'decomp_multiplicative_test_view',\n",
    "                         float_format='%.5f')\n",
    "components_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34523c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = y.to_frame()\n",
    "pivot['pred'] = results_model.model.predict(\n",
    "    splits.X_train[results_model.selected_features])\n",
    "pivot.describe().iloc[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cba707",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Plot TP, TN, FP and FN on PCA plot\n",
    "\n",
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f80aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(random_state=42)\n",
    "# bug: how does UMAP works with only one feature?\n",
    "# make sure to have two or more features?\n",
    "M_sel = len(results_model.selected_features)\n",
    "if M_sel > 1:\n",
    "    embedding = reducer.fit_transform(\n",
    "        X_scaled[results_model.selected_features])\n",
    "\n",
    "    embedding = pd.DataFrame(embedding,\n",
    "                             index=X_scaled.index,\n",
    "                             columns=['UMAP dimension 1', 'UMAP dimension 2'\n",
    "                                      ]).join(y.astype('category'))\n",
    "    display(embedding.head(3))\n",
    "else:\n",
    "    embedding = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad7133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['label'] = predictions.apply(\n",
    "    lambda x: njab.sklearn.scoring.get_label_binary_classification(\n",
    "        x['true'], x[model_name]),\n",
    "    axis=1)\n",
    "mask = predictions[['true', model_name]].sum(axis=1).astype(bool)\n",
    "predictions.loc[mask].sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de83e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled = scaler.transform(X_val)\n",
    "if embedding is not None:\n",
    "    embedding_val = pd.DataFrame(\n",
    "        reducer.transform(X_val_scaled[results_model.selected_features]),\n",
    "        index=X_val_scaled.index,\n",
    "        columns=['UMAP dimension 1', 'UMAP dimension 2'])\n",
    "    embedding_val.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5388726",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = (\n",
    "    y.to_frame('true')\n",
    "    # .join(get_score(clf=results_model.model, X=splits.X_train[results_model.selected_features], pos=1))\n",
    "    .join(score.rename('score')).join(\n",
    "        get_pred(results_model.model, splits.X_train[\n",
    "            results_model.selected_features]).rename(model_name)))\n",
    "pred_train['label'] = pred_train.apply(\n",
    "    lambda x: njab.sklearn.scoring.get_label_binary_classification(\n",
    "        x['true'], x[model_name]),\n",
    "    axis=1)\n",
    "pred_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af8f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = seaborn.color_palette(n_colors=4)\n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce405ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding is not None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "    for _embedding, ax, _title, _model_pred_label in zip(\n",
    "        [embedding, embedding_val], axes, [TRAIN_LABEL, TEST_LABEL],\n",
    "        [pred_train['label'], predictions['label']]):  # noqa: E129\n",
    "        ax = seaborn.scatterplot(\n",
    "            x=_embedding.iloc[:, 0],\n",
    "            y=_embedding.iloc[:, 1],\n",
    "            hue=_model_pred_label,\n",
    "            hue_order=['TN', 'TP', 'FN', 'FP'],\n",
    "            palette=[colors[0], colors[2], colors[1], colors[3]],\n",
    "            ax=ax)\n",
    "        ax.set_title(_title)\n",
    "\n",
    "    # files_out['pred_pca_labeled'] = FOLDER / 'pred_pca_labeled.pdf'\n",
    "    # njab.plotting.savefig(fig, files_out['pred_pca_labeled'])\n",
    "\n",
    "    files_out['umap_sel_feat.pdf'] = FOLDER / 'umap_sel_feat.pdf'\n",
    "    njab.plotting.savefig(ax.get_figure(), files_out['umap_sel_feat.pdf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf13052",
   "metadata": {},
   "source": [
    "### Interactive UMAP plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9063c8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding is not None:\n",
    "    embedding = embedding.join(X[results_model.selected_features])\n",
    "    embedding_val = embedding_val.join(X_val[results_model.selected_features])\n",
    "    embedding['label'], embedding_val['label'] = pred_train[\n",
    "        'label'], predictions['label']\n",
    "    embedding['group'], embedding_val['group'] = TRAIN_LABEL, TEST_LABEL\n",
    "    combined_embeddings = pd.concat([embedding, embedding_val])\n",
    "    combined_embeddings.index.name = 'ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf92031",
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding is not None:\n",
    "    cols = combined_embeddings.columns\n",
    "\n",
    "    TEMPLATE = 'none'\n",
    "    defaults = dict(width=1600, height=700, template=TEMPLATE)\n",
    "\n",
    "    fig = px.scatter(combined_embeddings.round(3).reset_index(),\n",
    "                     x=cols[0],\n",
    "                     y=cols[1],\n",
    "                     color='label',\n",
    "                     facet_col='group',\n",
    "                     hover_data=['ID'] + results_model.selected_features,\n",
    "                     **defaults)\n",
    "    fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[1]))\n",
    "\n",
    "    fname = FOLDER / 'umap_sel_feat.html'\n",
    "    files_out[fname.name] = fname\n",
    "    fig.write_html(fname)\n",
    "    print(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff423dd",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8f97b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCs_train, pca = njab_pca.run_pca(X_scaled[results_model.selected_features],\n",
    "                                  n_components=None)\n",
    "ax = njab_pca.plot_explained_variance(pca)\n",
    "ax.locator_params(axis='x', integer=True)\n",
    "\n",
    "fname = FOLDER / \"feat_sel_PCA_var_explained_by_PCs.pdf\"\n",
    "files_out[fname.name] = fname\n",
    "njab.plotting.savefig(ax.get_figure(), fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d3d73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCs_val = pca.transform(X_val_scaled[results_model.selected_features])\n",
    "PCs_val = pd.DataFrame(PCs_val,\n",
    "                       index=X_val_scaled.index,\n",
    "                       columns=PCs_train.columns)\n",
    "PCs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80546d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "if M_sel > 1:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "    for _embedding, ax, _title, _model_pred_label in zip(\n",
    "        [PCs_train, PCs_val], axes, [TRAIN_LABEL, TEST_LABEL],\n",
    "        [pred_train['label'], predictions['label']]):  # noqa: E129\n",
    "        ax = seaborn.scatterplot(\n",
    "            x=_embedding.iloc[:, 0],\n",
    "            y=_embedding.iloc[:, 1],\n",
    "            hue=_model_pred_label,\n",
    "            hue_order=['TN', 'TP', 'FN', 'FP'],\n",
    "            palette=[colors[0], colors[2], colors[1], colors[3]],\n",
    "            ax=ax)\n",
    "        ax.set_title(_title)\n",
    "\n",
    "    fname = FOLDER / 'pca_sel_feat.pdf'\n",
    "    files_out[fname.name] = fname\n",
    "    njab.plotting.savefig(ax.get_figure(), fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d50f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "if M_sel > 1:\n",
    "    max_rows = min(3, len(results_model.selected_features))\n",
    "    fig, axes = plt.subplots(max_rows,\n",
    "                             2,\n",
    "                             figsize=(8.3, 11.7),\n",
    "                             sharex=False,\n",
    "                             sharey=False,\n",
    "                             layout='constrained')\n",
    "\n",
    "    for axes_col, (_embedding, _title, _model_pred_label) in enumerate(\n",
    "            zip([PCs_train, PCs_val], [TRAIN_LABEL, TEST_LABEL],\n",
    "                [pred_train['label'], predictions['label']])):\n",
    "        _row = 0\n",
    "        axes[_row, axes_col].set_title(_title)\n",
    "        for (i, j) in itertools.combinations(range(max_rows), 2):\n",
    "            ax = seaborn.scatterplot(\n",
    "                x=_embedding.iloc[:, i],\n",
    "                y=_embedding.iloc[:, j],\n",
    "                hue=_model_pred_label,\n",
    "                hue_order=['TN', 'TP', 'FN', 'FP'],\n",
    "                palette=[colors[0], colors[2], colors[1], colors[3]],\n",
    "                ax=axes[_row, axes_col])\n",
    "            _row += 1\n",
    "\n",
    "    fname = FOLDER / f'pca_sel_feat_up_to_{max_rows}.pdf'\n",
    "    files_out[fname.name] = fname\n",
    "    njab.plotting.savefig(ax.get_figure(), fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d0229",
   "metadata": {},
   "source": [
    "### Features\n",
    "- top 3 scaled n_features_max (scatter)\n",
    "- or unscalled single features (swarmplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44680bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if M_sel > 1:\n",
    "    max_rows = min(3, len(results_model.selected_features))\n",
    "    fig, axes = plt.subplots(max_rows,\n",
    "                             2,\n",
    "                             figsize=(8.3, 11.7),\n",
    "                             sharex=False,\n",
    "                             sharey=False,\n",
    "                             layout='constrained')\n",
    "\n",
    "    for axes_col, (_embedding, _title, _model_pred_label) in enumerate(\n",
    "            zip([\n",
    "                X_scaled[results_model.selected_features],\n",
    "                X_val_scaled[results_model.selected_features]\n",
    "            ], [TRAIN_LABEL, TEST_LABEL],\n",
    "                [pred_train['label'], predictions['label']])):\n",
    "        _row = 0\n",
    "        axes[_row, axes_col].set_title(_title)\n",
    "        for (i, j) in itertools.combinations(range(max_rows), 2):\n",
    "            ax = seaborn.scatterplot(\n",
    "                x=_embedding.iloc[:, i],\n",
    "                y=_embedding.iloc[:, j],\n",
    "                hue=_model_pred_label,\n",
    "                hue_order=['TN', 'TP', 'FN', 'FP'],\n",
    "                palette=[colors[0], colors[2], colors[1], colors[3]],\n",
    "                ax=axes[_row, axes_col])\n",
    "            _row += 1\n",
    "\n",
    "    fname = FOLDER / f'sel_feat_up_to_{max_rows}.pdf'\n",
    "    files_out[fname.name] = fname\n",
    "    njab.plotting.savefig(ax.get_figure(), fname)\n",
    "else:\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(6, 2), layout='constrained')\n",
    "    single_feature = results_model.selected_features[0]\n",
    "    data = pd.concat([\n",
    "        X[single_feature].to_frame().join(\n",
    "            pred_train['label']).assign(group=TRAIN_LABEL),\n",
    "        X_val[single_feature].to_frame().join(\n",
    "            predictions['label']).assign(group=TEST_LABEL)\n",
    "    ])\n",
    "    ax = seaborn.swarmplot(data=data,\n",
    "                           x='group',\n",
    "                           y=single_feature,\n",
    "                           hue='label',\n",
    "                           ax=axes)\n",
    "    fname = FOLDER / f'sel_feat_{single_feature}.pdf'\n",
    "    files_out[fname.name] = fname\n",
    "    njab.plotting.savefig(ax.get_figure(), fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4107326d",
   "metadata": {},
   "source": [
    "## Annotation of Errors for manuel analysis\n",
    "\n",
    "Saved to excel table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989fdd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[results_model.selected_features].join(pred_train).to_excel(\n",
    "    writer, sheet_name='pred_train_annotated', float_format=\"%.3f\")\n",
    "X_val[results_model.selected_features].join(predictions).to_excel(\n",
    "    writer, sheet_name='pred_test_annotated', float_format=\"%.3f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dae149",
   "metadata": {},
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03584713",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463e3223",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_out"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
